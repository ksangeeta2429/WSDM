{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script contains code snippets to outline the process of generating embeddings for various fields in the songs.csv - songs, artist, composer, lyricist etc. We generate embeddings using the following method: Taking the one of the columns as input, we try to predict the output of the other 3 columns. There are two ways we can take the individual rows of the input column, as input - (1) char-rnn (2) A one hot encoding with each unique input element will be considered different from each other. Advantage of (1) is that it will capture textual level similarity between the names whereas (2) will be faster to train and will avoid capturing misleading features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/songs.csv').sample(n=1000).fillna('')\n",
    "print(\"Data Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by looking at number of distinct characters and number of distinct units in each columns. This will (hopefully) help in deciding which of the two approaches to choose from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unique_chars(data, column):\n",
    "    char_set = set([c for (i, row) in data.iterrows() for c in str(row[column])])\n",
    "    return len(char_set)\n",
    "\n",
    "# Some of the rows corresponding to a column have multiple values separated by '|'\n",
    "# character. We need to split and separate these multiple values\n",
    "\n",
    "def get_unique_entities(data, column):\n",
    "    unique = set([name.strip() for (i, row) in data.iterrows() for name in str(row[column]).split('|')])\n",
    "    return unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#num_chars_artist_name = get_unique_chars(data, 'artist_name')\n",
    "#num_chars_composer = get_unique_chars(data, 'composer')\n",
    "#num_chars_lyricist = get_unique_chars(data, 'lyricist')\n",
    "#num_chars_song_id = get_unique_chars(data, 'song_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#unique_artists = get_unique_entities(data, 'artist_name')\n",
    "#unique_composers = get_unique_entities(data, 'composer')\n",
    "#unique_lyricists = get_unique_entities(data, 'lyricist')\n",
    "#unique_songs = get_unique_entities(data, 'song_id')\n",
    "#print(\"Unique elements identified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_one_hot(batch_rows, mappers):\n",
    "    batch_size = batch_rows.shape[0]\n",
    "    one_hot = [None]*batch_rows.shape[1]\n",
    "    \n",
    "    for i in range(len(one_hot)):\n",
    "        one_hot[i] = np.zeros((batch_size, len(mappers[i])))\n",
    "    \n",
    "    row_num = 0\n",
    "    for (_, row) in batch_rows.iterrows():\n",
    "        for (i, element) in enumerate(row):\n",
    "            parts = [p.strip() for p in element.split('|')]\n",
    "            for p in parts:\n",
    "                one_hot[i][row_num][mappers[i][p]] = 1\n",
    "        row_num += 1\n",
    "            \n",
    "    return (one_hot[0], one_hot[1:])\n",
    "\n",
    "def generate_mapper(data, column):\n",
    "    unique_elements = get_unique_entities(data, column)\n",
    "    mapper = dict()\n",
    "    mapper['<unk>'] = 0\n",
    "    for u in unique_elements:\n",
    "        mapper[u] = len(mapper)\n",
    "    return mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artist_mapper = generate_mapper(data, 'artist_name')\n",
    "composer_mapper = generate_mapper(data, 'composer')\n",
    "lyricist_mapper = generate_mapper(data, 'lyricist')\n",
    "song_mapper = generate_mapper(data, 'song_id')\n",
    "mappers = [artist_mapper, composer_mapper, lyricist_mapper, song_mapper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#oh_artist = to_one_hot(data.artist_name, artist_mapper)\n",
    "#oh_composer = to_one_hot(data.composer, composer_mapper)\n",
    "#oh_lyricist = to_one_hot(data.lyricist, lyricist_mapper)\n",
    "#oh_song = to_one_hot(data.song_id, song_mapper)\n",
    "#print(\"Input-output matrices generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by creating a simple MLP model with one hidden layer. This corresponds to idea (2).\n",
    "\n",
    "Changeable parameters:\n",
    "\n",
    "* `num_hidden_units`\n",
    "* `hidden_activation`\n",
    "* `dropout`\n",
    "* `batch_size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(data, input_columns, target_columns, mappers, batch_size):\n",
    "    num_rows = data.shape[0]\n",
    "    num_inputs = len(input_columns)\n",
    "    num_outputs = len(target_columns)\n",
    "    all_columns = input_columns+target_columns\n",
    "    permutation = np.random.permutation(num_rows)\n",
    "    count = 0\n",
    "    while True:\n",
    "        batch_indices = permutation[count*batch_size:min((count+1)*batch_size, num_rows)]\n",
    "        batch = data[all_columns].iloc[batch_indices]\n",
    "        yield to_one_hot(batch, mappers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "input_generator = batch_generator(data, ['artist_name'],\n",
    "                    ['composer', 'lyricist', 'song_id'],\n",
    "                    mappers, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model compiled\n"
     ]
    }
   ],
   "source": [
    "input_col = 'artist_name'\n",
    "input_shape = len(mappers[0])\n",
    "output_shapes = [len(mappers[1]), len(mappers[2]), len(mappers[3])]\n",
    "num_hidden_units = 100\n",
    "hidden_activation = 'relu'\n",
    "dropout = 1.0\n",
    "batch_size = 64\n",
    "\n",
    "input_features = Input(shape = (input_shape,))\n",
    "hidden = Dropout(dropout)(\n",
    "    Dense(num_hidden_units,activation=hidden_activation)(input_features))\n",
    "output_0 = Dense(output_shapes[0], activation='softmax')(hidden)\n",
    "output_1 = Dense(output_shapes[1], activation='softmax')(hidden)\n",
    "output_2 = Dense(output_shapes[2], activation='softmax')(hidden)\n",
    "\n",
    "model = keras.models.Model(inputs = [input_features],\n",
    "                           outputs = [output_0, output_1, output_2])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(\"model compiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import IPython.display\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='./model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model-visualization](./model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "16/15 [==============================] - 0s - loss: 21.2527 - dense_6_loss: 8.7949 - dense_7_loss: 5.6012 - dense_8_loss: 6.8566 - dense_6_acc: 0.1699 - dense_7_acc: 0.5049 - dense_8_acc: 0.1865              \n",
      "Epoch 2/3\n",
      "16/15 [==============================] - 0s - loss: 20.6210 - dense_6_loss: 8.5756 - dense_7_loss: 5.3559 - dense_8_loss: 6.6894 - dense_6_acc: 0.6504 - dense_7_acc: 0.8760 - dense_8_acc: 0.7500     \n",
      "Epoch 3/3\n",
      "16/15 [==============================] - 0s - loss: 19.4475 - dense_6_loss: 8.1447 - dense_7_loss: 4.9364 - dense_8_loss: 6.3665 - dense_6_acc: 0.6904 - dense_7_acc: 0.8750 - dense_8_acc: 0.9551     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b73a56d8c88>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(input_generator, steps_per_epoch=data.shape[0]/batch_size, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo\n",
    "* Make code efficient for large scale\n",
    "* CSR matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
